{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430b902c-75aa-428a-9884-e0ff3e1cbf00",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          Commonly Used Terminology in Neural Network </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9996acc9-4972-4dc4-a67f-82b467afbab8",
   "metadata": {},
   "source": [
    "### Linear and Non-Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53804948-aef5-45fd-9209-f9f8a1547624",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       The neural network without any activation function in any of its layers is called a linear neural network. The neural network which has action functions like relu, sigmoid or tanh in any of its layer or even in more than one layer is called non-linear neural network. Introducing non-linearity in a neural network helps the model to learn complex pattern.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44904d1-72dd-4e4c-848f-f0a0dbe69c2e",
   "metadata": {},
   "source": [
    "### Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6b734-81fa-450d-913a-3aed8d60f471",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       An epoch in a neural network is a single pass through the entire training dataset. This means that the network will see each training example once during an epoch. The number of epochs is a hyperparameter that determines how many times the network will see the entire training dataset.\n",
    "\n",
    "The number of epochs required to train a neural network depends on a number of factors, including the size of the training dataset, the complexity of the network, and the learning rate. In general, a larger training dataset will require more epochs to train. A more complex network will also require more epochs to train. The learning rate controls how much the weights of the network are updated during each epoch. A higher learning rate will cause the network to learn faster, but it may also lead to overfitting.\n",
    "\n",
    "The best way to determine the number of epochs to use is to experiment with different values and see what works best for the specific problem. A common approach is to start with a small number of epochs and then increase the number of epochs until the performance of the network stops improving.\n",
    "\n",
    "Here is an example. Let's say we have a training dataset of 1000 examples and a neural network with 10 layers. If we set the number of epochs to 1, then the network will see each training example once during the epoch. If we set the number of epochs to 10, then the network will see each training example 10 times during the training process.\n",
    "\n",
    "It is important to note that more epochs is not always better. If the network is overfitting the training dataset, then increasing the number of epochs will not improve the performance of the network on the test dataset. In this case, it is better to use a technique called early stopping, which stops the training process when the performance of the network on the test dataset starts to deteriorate\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de1e2c-4e2c-41ec-8f03-e5cf10e12e55",
   "metadata": {},
   "source": [
    "### What are Parameters in Neural Networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcab95f-ceb2-40d3-8862-f6061e1b4720",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       <p>In neural networks, parameters refer to the learnable components of the model that are updated during the training process. Parameters are the key elements that define the behavior and functionality of a neural network. They are used to represent the weights and biases of the network's layers.</p>\n",
    "  \n",
    "  <b>Types of Parameters</b>\n",
    "  <p>There are two main types of parameters in neural networks:</p>\n",
    "  <ol>\n",
    "    <li><strong>Weights:</strong> Weights are the values associated with the connections between neurons in the network. Each connection between two neurons has an associated weight, which determines the strength or importance of that connection. Weights are adjusted during the training process to optimize the network's performance on a given task.</li>\n",
    "    <li><strong>Biases:</strong> Biases are additional learnable parameters that are added to each neuron in a layer. They provide an additional degree of freedom to the model, allowing it to fit the data more accurately. Biases help shift the activation function of each neuron and control the overall output of the neuron. Like weights, biases are updated during the training process.</li>\n",
    "  </ol>\n",
    "  <b>Training Neural Networks</b>\n",
    "  <p>Parameters in neural networks are typically initialized randomly, and their values are updated through an optimization algorithm such as gradient descent or its variants. The objective is to find the optimal set of parameter values that minimize the loss function, which measures the discrepancy between the model's predictions and the actual targets.</p>\n",
    "  <p>The process of training a neural network involves iteratively adjusting the parameters based on the gradients of the loss function with respect to those parameters. This iterative process aims to find the optimal parameter values that enable the network to make accurate predictions on unseen data.</p>\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259ef86-c514-4c10-affb-7d75449d7f35",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"images\\how_nn_works.jpg\" alt=\"how_nn_works\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f496b46-db26-4be3-a348-a866ad67e8a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Difference between loss & cost functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a319c8db-705f-4782-8f4b-04c95cbbaf80",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Generally, both terms refer to a function that measures the discrepancy or\n",
    "       error between the predicted outputs of a machine learning model and the\n",
    "       true labels. The goal is to minimize this discrepancy during the training\n",
    "       process.<br><br>\n",
    "       <b>Loss Function</b>:<br>\n",
    "       A loss function, also known as an error function or objective function, is \n",
    "       typically defined for an individual training example or data point. It\n",
    "       quantifies the error between the predicted output of the model and the\n",
    "       true label associated with that particular data point. In other words,\n",
    "       it measures how well the model performs on a single instance.<br><br>\n",
    "       The choice of a specific loss function depends on the type of machine\n",
    "       learning task being performed. For example, in classification tasks,\n",
    "       common loss functions include cross-entropy loss, hinge loss, or softmax loss.\n",
    "       For regression tasks, mean squared error (MSE) or mean absolute error (MAE)\n",
    "       are commonly used as loss functions.<br><br>\n",
    "       During training, the loss function is evaluated for each training example,\n",
    "       and the model's parameters are adjusted to minimize the cumulative error \n",
    "       across all examples. This optimization process, typically performed using\n",
    "       gradient descent or its variants, aims to find the set of model parameters\n",
    "       that minimizes the average loss over the entire training dataset.<br><br>\n",
    "       <b>Cost Function</b>:<br>\n",
    "       A cost function, also known as the objective function or the average \n",
    "       loss, measures the overall performance of the model by aggregating the\n",
    "       individual losses from all training examples. It represents the average\n",
    "       loss over the entire training dataset.<br><br>\n",
    "       The cost function is computed by taking the average or the sum (depending\n",
    "       on the specific context) of the individual losses over the training examples.\n",
    "       It provides a measure of how well the model is performing on average across\n",
    "       the entire dataset.<br><br>\n",
    "       The cost function is used in the training process to guide the \n",
    "       model's optimization. The goal is to find the optimal set of model\n",
    "       parameters that minimizes the cost function. By minimizing the cost function,\n",
    "       the model aims to reduce the overall error or discrepancy between its\n",
    "       predictions and the true labels across the entire dataset.<br><br>\n",
    "       In summary, the loss function quantifies the error between the predicted\n",
    "       outputs and true labels for individual training examples, while the cost\n",
    "       function measures the overall performance of the model by aggregating\n",
    "       the individual losses across the entire training dataset. The cost function\n",
    "       guides the model's optimization process by providing a single scalar\n",
    "       value to minimize during training.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb0723-1fb2-4555-81bb-7463cfe8bbe1",
   "metadata": {},
   "source": [
    "### Softmax Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a86a5c-8acd-42c9-ac7b-2cab1257a3c2",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       It is often used as the last activation function of a neural network to normalize the output of a network to a probability distribution over predicted output classes.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76142961-9d89-409b-a356-03667de80f17",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"images\\softmax.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcba91e-78bf-4298-abe2-553d739f9330",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$\\sigma(\\vec{Z})_i = \\frac{e^{Z_{i}}}{\\Sigma_{j=1}^{K}e^{Z_{j}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4fa33-1766-46f4-a680-b33742d8d014",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       Where,<br>\n",
    "       $\\sigma$ = Softmax<br>\n",
    "       $\\vec{Z}$ = Input Vector<br>\n",
    "       $e^{Z_{i}}$ = standard exponential function for input vector <br>\n",
    "       $K$ = number of classes in the multi-class classifier<br>\n",
    "       $e^{Z_{j}}$ = standard exponential function for output vector\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6032f-0bf7-46ed-b6e7-9b62df03f2c3",
   "metadata": {},
   "source": [
    "### Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabbc5d-789f-4640-80ab-9069691fd1e9",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       <b>TODO</b>: Yet to explore more <br>\n",
    "       Cross-entropy is a commonly used cost function for classification tasks, especially when the predicted outputs are probabilities. It measures the average logarithmic loss between the predicted class probabilities and the true labels.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1aaf1f-3fb5-4fcd-941e-d2d6a5fc9387",
   "metadata": {},
   "source": [
    "### logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec452a-49e4-4f97-a66d-1a1658e5e7c0",
   "metadata": {},
   "source": [
    "In a neural network for classification tasks, the output layer typically produces a set of raw scores or probabilities for each class. These scores are often referred to as \"logits.\" Each logit value represents the model's confidence for a specific class.\n",
    "\n",
    "In the given line of code, <i>outputs</i> represents the output of the like XLNet or bert model etc..,, which includes the <i>logits</i> among other things. By accessing <code>outputs.logits</code>, we obtain the raw scores for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a18ad1e-38c1-47d4-b610-d93b2ce247ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
