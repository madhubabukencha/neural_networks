{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          How Neural Networks Works and Learns</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breif Introduction on NN's Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       The neural network in the below image is also known as <i>Single Layer FeedForward\n",
    "       Neural Network</i> or <i>perceptron</i>. The neural network sums the all input values(x<sub>i</sub>) and weights(w<sub>i</sub>) and\n",
    "       then applies the some activation function and produces the predicted value(Å·). The predicted value compared with\n",
    "       actual value(y), if the difference is more then it will update the weights and repeates the same process. This\n",
    "       process also know as back propagation. To calculate the error we use something called <i>Cost Function</i>. Our goal\n",
    "       should be minimizing <i>Cost Function</i>. Just to note, a dataset might have millions of records, but a\n",
    "       neural network just have single set of weights for all\n",
    "       of those weights.\n",
    "   </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"images\\simple_neuron.png\" alt=\"simple_neuron\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y = Actual output value <br>\n",
    "&Ycirc;\t= Output value from perceptron <br>\n",
    "Cost Function (C) = 1/2(&Ycirc;-Y)<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Additional Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Below some answers for my questions from ChatGPT.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "       <b>At once do we feed single instance or multiple instances to the neural network?</b><br>\n",
    "       <p>When training a neural network, it is common to feed multiple instances, also known as samples or examples, at once. This approach is called \"mini-batch training.\"</p>\n",
    "\n",
    "<p>Mini-batch training involves dividing the training data into small groups or batches, where each batch contains multiple instances. The instances within a batch are processed together in parallel during each training iteration. The gradients calculated for each instance within the batch are averaged to update the network's weights and biases.</p>\n",
    "\n",
    "<p>The main advantages of using mini-batches are:</p>\n",
    "\n",
    "<ol>\n",
    "  <li>Efficiency: Processing instances in parallel allows for more efficient computation, especially when utilizing hardware acceleration like GPUs.</li>\n",
    "  <li>Generalization: By presenting the network with a variety of instances in each batch, it helps in capturing diverse patterns and reduces overfitting.</li>\n",
    "  <li>Stochasticity: The order of instances within a mini-batch is typically randomized, which introduces a certain level of stochasticity that can help the network avoid getting stuck in local minima.</li>\n",
    "</ol>\n",
    "\n",
    "<p>That being said, there are scenarios where single-instance training, also known as online learning, can be used. Online learning involves updating the network's parameters after each individual instance. This approach is useful when dealing with continuous data streams or when memory constraints prevent the use of mini-batches. However, it is less common compared to mini-batch training, which is widely used in most deep learning applications.</p>\n",
    "\n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;\">\n",
    "   <font size=3>\n",
    "    <b>I have 100 instances or sample, am I going to have 100 seperate weight for each instance in neural network?</b>\n",
    "    <p>No, in a typical neural network training scenario, you will not have separate weights for each individual instance. Instead, the weights of the neural network are shared across all instances.</p>\n",
    "\n",
    "<p>In a neural network, the weights and biases are the learnable parameters that are adjusted during the training process. These parameters are responsible for capturing the relationships and patterns in the training data. However, they are not specific to individual instances.</p>\n",
    "\n",
    "<p>During the training process, the network receives input instances, and their corresponding outputs or labels are used to calculate the loss. The loss is a measure of how well the network's predictions match the desired outputs. The gradients of the loss with respect to the network's parameters (weights and biases) are then calculated through a process called backpropagation.</p>\n",
    "\n",
    "<p>The gradients indicate the direction and magnitude of the adjustments needed to improve the network's performance. The weights and biases are then updated based on these gradients using optimization algorithms like gradient descent or its variants (e.g., Adam, RMSProp).</p>\n",
    "\n",
    "<p>The same set of weights and biases is used to process all instances in a mini-batch during each training iteration. The gradients calculated for each instance within the mini-batch are averaged or summed to update the shared weights and biases accordingly. This sharing of weights allows the network to generalize patterns learned from one instance to make predictions on new, unseen instances.</p>\n",
    "\n",
    "<p>In summary, while each instance contributes to the calculation of gradients and influences the weight updates, the neural network maintains a shared set of weights that are applied to all instances during training.</p>\n",
    "    \n",
    "   </font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources\n",
    "<ul>\n",
    "    <li><a href=\"https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications\">A list of cost functions used in neural networks, alongside applications</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
