{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed018360-2fa3-4172-a8f2-a0e9f9191bfc",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif;\n",
    "          text-align: center;\">\n",
    "          Implementation of NN in Python</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f0cc1-965c-467b-aa7f-39097e34e16c",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; \n",
    "          text-justify: inter-word;\n",
    "          font-size:17px;\">\n",
    "    The main goal of this notebook is implementing simple artificial neural network from end to end.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea440cd-e3c9-4d71-9d3e-6d3a20b4a4d5",
   "metadata": {},
   "source": [
    " ### <span style=\"color:#C738BD; font-weight: bold;\">Simple Manual Calculation of Layer</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c918808-59f2-485c-9ac5-7babc20038f7",
   "metadata": {},
   "source": [
    "<img src=\"images\\simple-nn-layer.png\" alt=\"simple-nn-layer\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521fadf-9157-4999-9a1f-b63e1e2a156c",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; \n",
    "          text-justify: inter-word;\n",
    "          font-size:17px;\">\n",
    "  Let's assume you have 4 input nodes and 3 output nodes. Now you have $4 * 3 = 12$ weights and 3 bias(to know more about bias look it in nn_terminology notebook)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74b0c707-9eb1-48ab-895e-b724abc3ddad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.42, 3.56, 5.63]\n"
     ]
    }
   ],
   "source": [
    "input = [1, 2.3, 3, 0.5]\n",
    "\n",
    "# Random weights\n",
    "weight_1 = [0.5, 0.4, 0.9, 0.6]\n",
    "weight_2 = [0.6, 0.2, 0.1, 0.4]\n",
    "weight_3 = [0.6, 0.1, 0.5, 0.6]\n",
    "\n",
    "#Bias\n",
    "bias_1 = 1\n",
    "bias_2 = 2\n",
    "bias_3 = 3\n",
    "\n",
    "# output of each output node\n",
    "output = [input[0] * weight_1[0] +  input[1] * weight_1[1] + input[2] * weight_1[2]+ input[3] * weight_1[3] + bias_1,\n",
    "          input[0] * weight_2[0] +  input[1] * weight_2[1] + input[2] * weight_2[2] + input[3] * weight_2[3] + bias_2,\n",
    "          input[0] * weight_3[0] +  input[1] * weight_3[1] + input[2] * weight_3[2] + input[3] * weight_3[3] + bias_3]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8b5ce-7571-4820-bd82-610234ea405e",
   "metadata": {},
   "source": [
    " ### <span style=\"color:#C738BD; font-weight: bold;\">With For loop</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613600d4-0990-4da0-aff7-de8d602ebee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.42, 3.56, 5.63]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2.3, 3, 0.5]\n",
    "\n",
    "# Random weights\n",
    "weights = [[0.5, 0.4, 0.9, 0.6], [0.6, 0.2, 0.1, 0.4], [0.6, 0.1, 0.5, 0.6]]\n",
    "biases = [1, 2, 3]\n",
    "\n",
    "layer_output = []\n",
    "for weight, bias in zip(weights, biases):\n",
    "    neuron_output = 0\n",
    "    for n_input, w in zip(inputs, weight):\n",
    "        neuron_output += n_input * w\n",
    "    neuron_output += bias\n",
    "    layer_output.append(neuron_output)\n",
    "\n",
    "print(layer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8205b1-8b6f-43a8-9b4c-81bf86709b63",
   "metadata": {},
   "source": [
    " ### <span style=\"color:#C738BD; font-weight: bold;\">Implementation with Numpy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cba8d54-e5eb-4016-a3d3-d335e3d457b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.42 3.56 5.63]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1, 2.3, 3, 0.5]\n",
    "\n",
    "# Random weights\n",
    "weights = [[0.5, 0.4, 0.9, 0.6], [0.6, 0.2, 0.1, 0.4], [0.6, 0.1, 0.5, 0.6]]\n",
    "biases = [1, 2, 3]\n",
    "\n",
    "# Dot product\n",
    "# The dimention is very important while performing dot product\n",
    "# inputs has (4, 1) and weights has (3, 4), so meet dot product criteria either do transportation of weight or\n",
    "# do weights * inputs\n",
    "layer_output = np.dot(weights, inputs) + biases\n",
    "print(layer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2819057d-f7b8-4968-b426-3957ef962144",
   "metadata": {},
   "source": [
    " ### <span style=\"color:#C738BD; font-weight: bold;\">Batches, Layer and Objects</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733d01d-e302-46e1-8fed-2d27490ee734",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; \n",
    "          text-justify: inter-word;\n",
    "          font-size:17px;\">\n",
    "  In this sectioin, we are going to feed a batch of inputs. Batch of inputs helps for better\n",
    "  generalization. When you feed a batch of inputs, the network performs the same operations \n",
    "  (using the same weights) on all inputs simultaneously. This parallel processing is what makes\n",
    "  batching computationally efficient, especially on GPUs. During training, the network updates its\n",
    "  weights based on the error calculated from the entire batch.The updates aim to improve performance\n",
    "  across all inputs in the batch, leading to more stable and efficient training.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74845081-cac9-4632-ad20-7deca8b98bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has size of 4 X 4\n",
    "batch_of_inputs = [[1, 2, 3, 4],\n",
    "                   [0.5, 1, 3, 0.4],\n",
    "                   [4.5, 3, 1, 0.9],\n",
    "                   [0.5, 0.4, 2, 0.2]]\n",
    "\n",
    "# Random weights\n",
    "# It has size of 3 X 4\n",
    "weights = [[0.5, 0.4, 0.9, 0.6], \n",
    "           [0.6, 0.2, 0.1, 0.4], \n",
    "           [0.6, 0.1, 0.5, 0.6]]\n",
    "\n",
    "biases = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140487a3-327f-40cb-9150-8de54cb2f621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.4 , 2.9 , 4.7 ],\n",
       "       [3.59, 0.96, 2.14],\n",
       "       [4.89, 3.76, 4.04],\n",
       "       [2.33, 0.66, 1.46]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Performing transpose to make it compatible with matrix multiplication\n",
    "np.dot(batch_of_inputs, np.transpose(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104caf58-c5f4-4c1f-8733-c471cb1240d3",
   "metadata": {},
   "source": [
    "In the output matrix:\n",
    "\n",
    "\n",
    "\\begin{bmatrix}\n",
    "6.4 & 2.9 & 4.7 \\\\\n",
    "3.59 & 0.96 & 2.14 \\\\\n",
    "4.89 & 3.76 & 4.04 \\\\\n",
    "2.33 & 0.66 & 1.46\n",
    "\\end{bmatrix}\n",
    "\n",
    "\n",
    "- Each **row** corresponds to an input sample from the `batch_of_inputs`.\n",
    "- Each **column** corresponds to a neuron in the layer (since there are 3 neurons, we have 3 columns).\n",
    "- The values in the matrix represent the weighted sum of inputs for each neuron before applying any activation function.\n",
    "\n",
    "For example:\n",
    "- The first row `[6.4, 2.9, 4.7]` represents the weighted sum of inputs for each of the 3 neurons for the **first input sample** `[1, 2, 3, 4]`.\n",
    "- The second row `[3.59, 0.96, 2.14]` represents the weighted sum of inputs for the 3 neurons for the **second input sample** `[0.5, 1, 3, 0.4]`.\n",
    "\n",
    "Thus, each row in the output represents the pre-activation outputs of all neurons for a single input sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8959a5-774f-4698-b6cb-d62d6495c597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
