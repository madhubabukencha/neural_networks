{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed018360-2fa3-4172-a8f2-a0e9f9191bfc",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif;\n",
    "          text-align: center;\">\n",
    "          Implementation of NN in Python</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f0cc1-965c-467b-aa7f-39097e34e16c",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; \n",
    "          text-justify: inter-word;\n",
    "          font-size:17px;\">\n",
    "    The main goal of this notebook is implementing simple artificial neural network from end to end.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea440cd-e3c9-4d71-9d3e-6d3a20b4a4d5",
   "metadata": {},
   "source": [
    " ### <span style=\"color:#C738BD; font-weight: bold;\">Simple Manual Calculation of Layer</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c918808-59f2-485c-9ac5-7babc20038f7",
   "metadata": {},
   "source": [
    "<img src=\"images\\basic_nn.png\" alt=\"basic_nn\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521fadf-9157-4999-9a1f-b63e1e2a156c",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; \n",
    "          text-justify: inter-word;\n",
    "          font-size:17px;\">\n",
    "  Let's assume you have 4 input nodes and 3 output nodes. Now you have $4 * 3 = 12$ weights and 3 bias(to know more about bias look it in nn_terminology notebook)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74b0c707-9eb1-48ab-895e-b724abc3ddad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.42, 3.56, 5.63]\n"
     ]
    }
   ],
   "source": [
    "input = [1, 2.3, 3, 0.5]\n",
    "\n",
    "# Random weights\n",
    "weight_1 = [0.5, 0.4, 0.9, 0.6]\n",
    "weight_2 = [0.6, 0.2, 0.1, 0.4]\n",
    "weight_3 = [0.6, 0.1, 0.5, 0.6]\n",
    "\n",
    "#Bias\n",
    "bias_1 = 1\n",
    "bias_2 = 2\n",
    "bias_3 = 3\n",
    "\n",
    "# output of each output node\n",
    "output = [input[0] * weight_1[0] +  input[1] * weight_1[1] + input[2] * weight_1[2]+ input[3] * weight_1[3] + bias_1,\n",
    "          input[0] * weight_2[0] +  input[1] * weight_2[1] + input[2] * weight_2[2] + input[3] * weight_2[3] + bias_2,\n",
    "          input[0] * weight_3[0] +  input[1] * weight_3[1] + input[2] * weight_3[2] + input[3] * weight_3[3] + bias_3]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8b5ce-7571-4820-bd82-610234ea405e",
   "metadata": {},
   "source": [
    " ### <span style=\"color:#C738BD; font-weight: bold;\">With For loop</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613600d4-0990-4da0-aff7-de8d602ebee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.42, 3.56, 5.63]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2.3, 3, 0.5]\n",
    "\n",
    "# Random weights\n",
    "weights = [[0.5, 0.4, 0.9, 0.6], [0.6, 0.2, 0.1, 0.4], [0.6, 0.1, 0.5, 0.6]]\n",
    "biases = [1, 2, 3]\n",
    "\n",
    "layer_output = []\n",
    "for weight, bias in zip(weights, biases):\n",
    "    neuron_output = 0\n",
    "    for n_input, w in zip(inputs, weight):\n",
    "        neuron_output += n_input * w\n",
    "    neuron_output += bias\n",
    "    layer_output.append(neuron_output)\n",
    "\n",
    "print(layer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8205b1-8b6f-43a8-9b4c-81bf86709b63",
   "metadata": {},
   "source": [
    " ### <span style=\"color:#C738BD; font-weight: bold;\">Implementation with Numpy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cba8d54-e5eb-4016-a3d3-d335e3d457b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.42 3.56 5.63]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1, 2.3, 3, 0.5]\n",
    "\n",
    "# Random weights\n",
    "weights = [[0.5, 0.4, 0.9, 0.6], [0.6, 0.2, 0.1, 0.4], [0.6, 0.1, 0.5, 0.6]]\n",
    "biases = [1, 2, 3]\n",
    "\n",
    "# Dot product\n",
    "# The dimention is very important while performing dot product\n",
    "# inputs has (4, 1) and weights has (3, 4), so meet dot product criteria either do transportation of weight or\n",
    "# do weights * inputs\n",
    "layer_output = np.dot(weights, inputs) + biases\n",
    "print(layer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2819057d-f7b8-4968-b426-3957ef962144",
   "metadata": {},
   "source": [
    " ### <span style=\"color:#C738BD; font-weight: bold;\">Batches, Layer and Objects</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733d01d-e302-46e1-8fed-2d27490ee734",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; \n",
    "          text-justify: inter-word;\n",
    "          font-size:17px;\">\n",
    "  In this sectioin, we are going to feed a batch of inputs. Batch of inputs helps for better\n",
    "  generalization. When you feed a batch of inputs, the network performs the same operations \n",
    "  (using the same weights) on all inputs simultaneously. This parallel processing is what makes\n",
    "  batching computationally efficient, especially on GPUs. During training, the network updates its\n",
    "  weights based on the error calculated from the entire batch.The updates aim to improve performance\n",
    "  across all inputs in the batch, leading to more stable and efficient training.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74845081-cac9-4632-ad20-7deca8b98bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has size of 4 X 4\n",
    "batch_of_inputs = [[1, 2.3, 3, 0.5],\n",
    "                   [0.5, 1, 3, 0.4],\n",
    "                   [4.5, 3, 1, 0.9],\n",
    "                   [0.5, 0.4, 2, 0.2]]\n",
    "\n",
    "# Random weights\n",
    "# It has size of 3 X 4\n",
    "weights = [[0.5, 0.4, 0.9, 0.6], \n",
    "           [0.6, 0.2, 0.1, 0.4], \n",
    "           [0.6, 0.1, 0.5, 0.6]]\n",
    "\n",
    "biases = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "140487a3-327f-40cb-9150-8de54cb2f621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.42, 1.56, 2.63],\n",
       "       [3.59, 0.96, 2.14],\n",
       "       [4.89, 3.76, 4.04],\n",
       "       [2.33, 0.66, 1.46]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Performing transpose to make it compatible with matrix multiplication\n",
    "output =  np.dot(batch_of_inputs, np.transpose(weights))\n",
    "# NOTE: The number of batches of input equals to number of rows of the output\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104caf58-c5f4-4c1f-8733-c471cb1240d3",
   "metadata": {},
   "source": [
    "In the output matrix:\n",
    "\n",
    "\n",
    "\\begin{bmatrix}\n",
    "4.42 & 1.56 & 2.63 \\\\\n",
    "3.59 & 0.96 & 2.14 \\\\\n",
    "4.89 & 3.76 & 4.04 \\\\\n",
    "2.33 & 0.66 & 1.46\n",
    "\\end{bmatrix}\n",
    "\n",
    "\n",
    "- Each **row** corresponds to an input sample from the `batch_of_inputs`.\n",
    "- Each **column** corresponds to a neuron in the layer (since there are 3 neurons, we have 3 columns).\n",
    "- The values in the matrix represent the weighted sum of inputs for each neuron before applying any activation function.\n",
    "\n",
    "For example:\n",
    "- The first row `[6.4, 2.9, 4.7]` represents the weighted sum of inputs for each of the 3 neurons for the **first input sample** `[1, 2, 3, 4]`.\n",
    "- The second row `[3.59, 0.96, 2.14]` represents the weighted sum of inputs for the 3 neurons for the **second input sample** `[0.5, 1, 3, 0.4]`.\n",
    "\n",
    "Thus, each row in the output represents the pre-activation outputs of all neurons for a single input sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8959a5-774f-4698-b6cb-d62d6495c597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.42, 3.56, 5.63],\n",
       "       [4.59, 2.96, 5.14],\n",
       "       [5.89, 5.76, 7.04],\n",
       "       [3.33, 2.66, 4.46]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you see carefully, first row output matches with single input output\n",
    "output + biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f7e714-9adb-499b-8293-38dd7947dff0",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#40A578; font-weight: bold;\">Adding Additional Layer</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531826a2-01a0-4cf4-bac2-204cb7d55ced",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; \n",
    "          text-justify: inter-word;\n",
    "          font-size:17px;\">\n",
    "  Adding an additional layer with 3 neurons. The output of second layer going to act as an input now, so we just only need to defined weights and bias.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0dfc87d-efc3-43a0-9c64-2f84c975f495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.461  2.6316 3.408 ]\n",
      " [0.271  2.3608 3.001 ]\n",
      " [1.531  2.5488 4.051 ]\n",
      " [0.391  1.8352 2.457 ]]\n"
     ]
    }
   ],
   "source": [
    "# It has size of 4 X 4\n",
    "batch_of_inputs = [[1, 2.3, 3, 0.5],\n",
    "                   [0.5, 1, 3, 0.4],\n",
    "                   [4.5, 3, 1, 0.9],\n",
    "                   [0.5, 0.4, 2, 0.2]]\n",
    "\n",
    "# Random weights, It has size of 3 X 4\n",
    "# Since we have 4 input nodes we are going to have 4 columns and\n",
    "# we have 3 output nodes so we are going to have 3 rows \n",
    "weights1 = [[0.5, 0.4, 0.9, 0.6], \n",
    "           [0.6, 0.2, 0.1, 0.4],\n",
    "           [0.6, 0.1, 0.5, 0.6]]\n",
    "\n",
    "# Since our input layer has 3 neurons we are going to have 3 columns\n",
    "# and since we have 3 neurons in the output layer we are going to have 3 rows.\n",
    "weights2 = [[-0.1, 0.7, -0.3],\n",
    "            [0.4, -0.2, 0.12],\n",
    "            [0.3, 0.1, 0.2]]\n",
    "\n",
    "bias1 = [1, 2, 3]\n",
    "bias2 = [0.2, 0.5, 0.3]\n",
    "\n",
    "layer1_output = np.dot(batch_of_inputs, np.array(weights1).T) + bias1\n",
    "layer2_output = np.dot(layer1_output, np.array(weights2).T) + bias2\n",
    "print(layer2_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c3e2b-1af6-488b-bcb5-184fb3687463",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#40A578; font-weight: bold;\">Converting Into an Object</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f09ac12b-1aa1-49f9-9ea7-18709affd03d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1152811   7.69522063  2.81115045  2.52504874  3.71647637]\n",
      " [ 0.47034874  6.11061917  2.53906165  1.50747988  2.3343289 ]\n",
      " [ 5.45075238  7.44991736  4.52664459 10.17779879  9.31098353]\n",
      " [ 0.84593703  3.7874768   1.90986991  1.38512263  1.81492571]]\n",
      "[[18.55041775 -4.73602561]\n",
      " [13.49148266 -4.77259248]\n",
      " [17.53603842  3.22630427]\n",
      " [ 8.29456105 -2.62815743]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X = [[1, 2.3, 3, 0.5],\n",
    "     [0.5, 1, 3, 0.4],\n",
    "     [4.5, 3, 1, 0.9],\n",
    "     [0.5, 0.4, 2, 0.2]]\n",
    "\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        \"\"\"\n",
    "        :param n_inputs: Input size or num of features, in our example we have 4 features\n",
    "        :type  n_inputs: int\n",
    "        :param n_neurons: Number of neurons in the ouput layer\n",
    "        :type  n_neurons: int\n",
    "        \"\"\"\n",
    "        self.weights = np.random.randn(n_inputs, n_neurons)\n",
    "        self.bias = np.zeros((1, n_neurons))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.bias\n",
    "    \n",
    "\n",
    "layer1 = LayerDense(4, 5)\n",
    "layer2 = LayerDense(5, 2)\n",
    "\n",
    "layer1.forward(X)\n",
    "layer2.forward(layer1.output)\n",
    "print(layer1.output)\n",
    "print(layer2.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3daf01-27ba-40bf-b57e-d358e598bd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
